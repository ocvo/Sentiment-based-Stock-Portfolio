{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0044663b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T11:48:10.283813Z",
     "start_time": "2021-10-16T11:48:08.823728Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b04f58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T11:48:10.299841Z",
     "start_time": "2021-10-16T11:48:10.284818Z"
    }
   },
   "outputs": [],
   "source": [
    "path_news = './stock/usa/politicals_news/'\n",
    "list_file_news = [os.path.join(path_news, filename) for filename in os.listdir(path_news) if os.path.isfile(os.path.join(path_news, filename))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9648d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T09:14:45.596776Z",
     "start_time": "2021-10-10T09:14:45.587641Z"
    }
   },
   "outputs": [],
   "source": [
    "# def pos_tag_text(text):\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     pos_dict = {\n",
    "#         'J' : wordnet.ADJ, \n",
    "#         'V' : wordnet.VERB, \n",
    "#         'N' : wordnet.NOUN, \n",
    "#         'R' : wordnet.ADV\n",
    "#     }\n",
    "\n",
    "#     text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "#     token = word_tokenize(text.lower())\n",
    "#     words_list = [w for w in token if not w in stop_words]\n",
    "#     pos_tagged = pos_tag(words_list)\n",
    "#     pos_data = [(w, pos_dict.get(p[0])) for w, p in pos_tagged]\n",
    "    \n",
    "#     return pos_data\n",
    "\n",
    "# def lemmatize_text(pos_data):\n",
    "#     wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#     lemma_rew = \" \"\n",
    "#     for word, pos in pos_data:\n",
    "#         if pos is None:\n",
    "#             lemma = word\n",
    "#             lemma_rew = lemma_rew + \" \" + lemma\n",
    "#         else:\n",
    "#             lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "#             lemma_rew = lemma_rew + \" \" + lemma\n",
    "            \n",
    "#     return lemma_rew.strip()\n",
    "\n",
    "# def sentiwordnet_analysis(pos_data):\n",
    "#     wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#     tokens_count = 0\n",
    "#     score_pos = 0\n",
    "#     score_neg = 0\n",
    "#     score_obj = 0\n",
    "#     for word, pos in pos_data:\n",
    "#         if not pos:\n",
    "#             continue\n",
    "            \n",
    "#         lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "#         if not lemma:\n",
    "#             continue\n",
    "        \n",
    "#         synsets = wordnet.synsets(lemma, pos=pos)\n",
    "#         if not synsets:\n",
    "#             continue\n",
    "            \n",
    "#         # Take the first sense, the most common\n",
    "#         synset = synsets[0]\n",
    "#         swn_synset = swn.senti_synset(synset.name())\n",
    "        \n",
    "#         score_pos += swn_synset.pos_score()\n",
    "#         score_neg += swn_synset.neg_score()\n",
    "#         score_obj += swn_synset.obj_score()\n",
    "        \n",
    "#         tokens_count += 1\n",
    "    \n",
    "#     score_total = score_pos - score_neg\n",
    "    \n",
    "#     return (score_pos, score_neg, score_obj, score_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ec3212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T11:50:02.440881Z",
     "start_time": "2021-10-16T11:50:02.433879Z"
    }
   },
   "outputs": [],
   "source": [
    "def vader_sentiment_article(list_word):\n",
    "#     list_word = text.replace('\\t', ' ').replace('\\n', ' ').split(' ')\n",
    "    df_list_word = pd.DataFrame(list_word, columns=['words'])\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df_list_word['vader_analysis'] = df_list_word['words'].apply(analyzer.polarity_scores)\n",
    "    df_list_word['pos'] = df_list_word['vader_analysis'].apply(lambda x: x['pos'])\n",
    "    df_list_word['neg'] = df_list_word['vader_analysis'].apply(lambda x: x['neg'])\n",
    "    \n",
    "    sum_diff = (df_list_word['pos'] - df_list_word['neg']).sum()\n",
    "    if sum_diff < 0:\n",
    "        return -1\n",
    "    if sum_diff > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def make_sentiment_features(df):\n",
    "    print(df.shape)\n",
    "    df['article_concat_split'] = df['article_title'].apply(lambda x: x.replace('\\t', ' ').replace('\\n', ' ').split(' '))\n",
    "    df['vader_sentiment'] = df['article_concat_split'].apply(vader_sentiment_article)\n",
    "    df['vader_sentiment_pos'] = (df['vader_sentiment'] > 0).astype('int')\n",
    "    df['vader_sentiment_neg'] = (df['vader_sentiment'] < 0).astype('int')\n",
    "    \n",
    "#     df['lm_sentiment'] = df['article_concat_split'].apply(lm_sentiment_article)\n",
    "#     df['lm_sentiment_pos'] = (df['lm_sentiment'] > 0).astype('int')\n",
    "#     df['lm_sentiment_neg'] = (df['lm_sentiment'] < 0).astype('int')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def daily_sentiment_score(pos_num, neg_num):\n",
    "    if pos_num > neg_num:\n",
    "        return 2 * pos_num / (pos_num + neg_num) - 1\n",
    "    \n",
    "    if pos_num < neg_num:\n",
    "        return 1 - 2  * neg_num / (pos_num + neg_num)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f83696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T11:56:20.530921Z",
     "start_time": "2021-10-16T11:50:03.820193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84cc0f4418d44a6aa1a566fac3e2b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 2)\n",
      "(848, 2)\n",
      "(1158, 2)\n",
      "(4743, 2)\n",
      "(3136, 2)\n",
      "(1644, 2)\n",
      "(1549, 2)\n",
      "(3131, 2)\n",
      "(2503, 2)\n",
      "(1835, 2)\n",
      "(2578, 2)\n",
      "(5514, 2)\n",
      "(3314, 2)\n",
      "(2686, 2)\n",
      "(3112, 2)\n",
      "(4534, 2)\n",
      "(2077, 2)\n"
     ]
    }
   ],
   "source": [
    "df = None\n",
    "filter_start_time = '2005-01-01'\n",
    "\n",
    "for file in tqdm(list_file_news):\n",
    "    basename = os.path.basename(file)\n",
    "    os.path.splitext(basename)\n",
    "    file_name, file_extension = os.path.splitext(basename)\n",
    "    if file_extension != '.csv':\n",
    "        continue\n",
    "        \n",
    "    df_news = pd.read_csv(file, header=None)\n",
    "    df_news.columns = ['article_title', 'time']\n",
    "    df_news.loc[df_news['time'].str.contains('ago'), 'time'] = 'Aug 10, 2021'\n",
    "    df_news['Date'] = pd.to_datetime(df_news['time'])\n",
    "    df_news = df_news[df_news['Date'] >= filter_start_time]\n",
    "    \n",
    "    if len(df_news) == 0:\n",
    "        continue\n",
    "    \n",
    "    df_news.drop_duplicates(subset=['Date', 'article_title'], keep='first', inplace=True)\n",
    "    df_news.drop('time', axis=1, inplace=True)\n",
    "    \n",
    "    df_news = df_news[['Date', 'article_title']]\n",
    "\n",
    "    df_news = make_sentiment_features(df_news)\n",
    "    \n",
    "    if df is None:\n",
    "        df = df_news.copy()\n",
    "    else:\n",
    "        df = pd.concat([df, df_news], axis=0)\n",
    "    \n",
    "    del df_news\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b3d995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T12:06:45.945937Z",
     "start_time": "2021-10-16T12:06:45.924361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_concat_split</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>vader_sentiment_pos</th>\n",
       "      <th>vader_sentiment_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-08-01</td>\n",
       "      <td>'One of them made cuts in my penis. I was in a...</td>\n",
       "      <td>['One, of, them, made, cuts, in, my, penis., I...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                      article_title  \\\n",
       "0 2005-08-01  'One of them made cuts in my penis. I was in a...   \n",
       "\n",
       "                                article_concat_split  vader_sentiment  \\\n",
       "0  ['One, of, them, made, cuts, in, my, penis., I...               -1   \n",
       "\n",
       "   vader_sentiment_pos  vader_sentiment_neg  \n",
       "0                    0                    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493ec1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T12:07:28.546006Z",
     "start_time": "2021-10-16T12:07:28.467829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>daily_sentiment_score_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  daily_sentiment_score_vader\n",
       "0 2005-01-02                         -1.0\n",
       "1 2005-01-03                          0.0\n",
       "2 2005-01-05                         -1.0\n",
       "3 2005-01-06                         -1.0\n",
       "4 2005-01-07                         -1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = df.groupby(['Date']) \\\n",
    "    .agg(vader_sentiment_pos=('vader_sentiment_pos', 'sum'), \n",
    "         vader_sentiment_neg=('vader_sentiment_neg', 'sum'),) \\\n",
    "    .reset_index()\n",
    "\n",
    "df_sentiment['daily_sentiment_score_vader'] = df_sentiment \\\n",
    "    .apply(lambda x: daily_sentiment_score(x['vader_sentiment_pos'], x['vader_sentiment_neg']), axis=1)\n",
    "\n",
    "df_sentiment[['Date', 'daily_sentiment_score_vader']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980485eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T12:07:45.767385Z",
     "start_time": "2021-10-16T12:07:45.700608Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sentiment[['Date', 'daily_sentiment_score_vader']] \\\n",
    "    .to_csv('./exported_data/news_sentiment_analysis/us_political_news_sentiment_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d57541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
